[
  {
    "path": "posts/2021-07-07-comparing-drinking-water-quality-time-series-using-generalized-additive-mixed-models/",
    "title": "Comparing drinking water quality time series using generalized additive mixed models",
    "description": "Revisiting work from 2016 as an application of a GAMM.",
    "author": [
      {
        "name": "Ben Trueman",
        "url": {}
      }
    ],
    "date": "2021-07-07",
    "categories": [],
    "contents": "\nIn a 2016 paper (Trueman and Gagnon 2016), I evaluated the effect of cast iron distribution mains on the lead concentrations due to lead pipes downstream from those mains. This question has relevance for minimizing lead in drinking water and for prioritizing lead pipe replacement; if a lead pipe is connected to an unlined iron distribution main, lead levels reaching the consumer are likely to be higher.\nIn the paper, I used the arima() function in R with a matrix of external regressors to account for the effect of the distribution main and autocorrelation in the time series of lead concentrations. But linear regression was only a rough approximation of the behaviour of the concentration time series, and I think using a generalized additive model would have been a better choice. Here, I revisit these data, using mgcv::gamm() to fit a generalized additive mixed model and nlme::corCAR1() to include a continuous time first-order autoregressive error structure.\nI also make use of the material in an excellent blog post by Gavin Simpson to compute a simultaneous 95% confidence interval for the model.\nFirst, I used Gavin Simpson’s approach to write a function that calculates the critical value used to construct simultaneous confidence intervals:\n\n\nrmvn <- function(n, mu, sig) { # generate multivariate normal random deviates\n  L <- mgcv::mroot(sig)\n  m <- ncol(L)\n  t(mu + L %*% matrix(rnorm(m*n), m, n))\n}\n\nsimul_critval <- function(model, N = 10000) {\n  Vb <- vcov(model)\n  pred <- predict(model, se.fit = TRUE)\n  se.fit <- pred$se.fit\n  BUdiff <- rmvn(N, mu = rep(0, nrow(Vb)), sig = Vb)\n  Cg <- predict(model, type = \"lpmatrix\")\n  simDev <- Cg %*% t(BUdiff)\n  absDev <- abs(sweep(simDev, 1, se.fit, FUN = \"/\"))\n  masd <- apply(absDev, 2, max)\n  quantile(masd, prob = 0.95, type = 8)\n}\n\n\n\nNext, I built the model, using s() to fit a separate smooth to each category of lead time series. (The categories are defined by the distribution main—PVC or cast iron—and the lead pipe configuration—full lead or half lead half copper.) In this model, the smooths differ in their flexibility and shape (Pedersen et al. 2019). I use tidyr::nest() to allow for list columns that include the model and predicted values along with the data.\n\n\nfe_gam <- jdk_pl %>% \n  filter(fraction == \"total\") %>% \n  mutate_if(is.character, factor) %>% \n  mutate(lsl_grp = interaction(pipe_config, main)) %>% \n  arrange(fraction, lsl, time_d) %>% \n  group_by(fraction) %>% \n  nest() %>% \n  ungroup() %>% \n  mutate(\n    model = map(\n      data,\n      ~ mgcv::gamm(\n        log(pb_ppb) ~ s(time_d, by = lsl_grp) + main + pipe_config, # model I\n        correlation = nlme::corCAR1(form = ~ time_d | lsl),\n        method = \"REML\",\n        data = .x\n      )\n    )\n  )\n\n\n\nNext, I predicted from the model over the range of x values, and constructed the 95% confidence band using Simpson’s method.\n\n\nfe_gam <- fe_gam %>% \n  mutate(\n    preds = map2(\n      model, data, \n      ~ predict(.x$gam, newdata = .y, se = TRUE)\n    ),\n    preds = map2(\n      preds, model, \n      ~ tibble(fit = .x$fit, se_fit = .x$se.fit) %>% \n        mutate(\n          lwr = fit - simul_critval(.y$gam) * se_fit,\n          upr = fit + simul_critval(.y$gam) * se_fit,\n          fit = fit\n        ) %>% \n        mutate_at(vars(c(fit, lwr, upr)), exp)\n    )\n  )\n\n\n\nHere are the data, the fitted model, and the simultaneous 95% confidence bands:\n\n\n\nThe model does a reasonably good job—but not a perfect job—accounting for autocorrelation in the time series. “Raw” and “normalized” residuals are defined in the help file to nlme::residuals.lme() under type. Essentially, raw residuals represent the difference between the observed and fitted values, while normalized residuals account for the estimated error structure (here, continuous time first-order autoregressive). The grey shaded band in the figure below represents a 95% confidence interval on the autocorrelation of white Gaussian noise.\n\n\n\nThe natural log transformation yields a model with residuals that are approximately normal.\n\n\n\nFinally, let’s have a look at the model summary. The effect of the distribution main is statistically significant, as is the effect of pipe configuration (which we’re less concerned about here). Based on the retransformed coefficient (exponentiating and subtracting one), the model estimates that lead release is 51% lower when the distribution main supplying the lead pipe is plastic as opposed to iron.\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nlog(pb_ppb) ~ s(time_d, by = lsl_grp) + main + pipe_config\n\nParametric coefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             5.44408    0.07202  75.587   <2e-16 ***\nmainpvc                -0.70833    0.08333  -8.501   <2e-16 ***\npipe_configpartial lsl -0.84626    0.08333 -10.156   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                                    edf Ref.df      F p-value    \ns(time_d):lsl_grpfull lsl.iron    1.000  1.000  7.718 0.00558 ** \ns(time_d):lsl_grppartial lsl.iron 1.000  1.000  9.904 0.00170 ** \ns(time_d):lsl_grpfull lsl.pvc     1.000  1.000 22.649   3e-06 ***\ns(time_d):lsl_grppartial lsl.pvc  3.444  3.444  3.345 0.00880 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.564   \n  Scale est. = 0.33246   n = 954\n\n\n\n\nPedersen, Eric J., David L. Miller, Gavin L. Simpson, and Noam Ross. 2019. “Hierarchical Generalized Additive Models in Ecology: An Introduction with Mgcv.” PeerJ 7 (May): e6876. https://doi.org/10.7717/peerj.6876.\n\n\nTrueman, Benjamin F., and Graham A. Gagnon. 2016. “Understanding the Role of Particulate Iron in Lead Release to Drinking Water.” Environmental Science & Technology 50 (17): 9053–60. https://doi.org/10.1021/acs.est.6b01153.\n\n\n\n\n",
    "preview": "posts/2021-07-07-comparing-drinking-water-quality-time-series-using-generalized-additive-mixed-models/comparing-drinking-water-quality-time-series-using-generalized-additive-mixed-models_files/figure-html5/plot-1.png",
    "last_modified": "2021-07-12T10:24:31-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-05-non-parametric-matched-pair-testing-with-left-censored-data/",
    "title": "Non-parametric matched pair testing with left-censored data",
    "description": "Comparing two groups of measurements when some values are below a detection limit.",
    "author": [
      {
        "name": "Ben Trueman",
        "url": {}
      }
    ],
    "date": "2021-07-05",
    "categories": [],
    "contents": "\nThere are few options in R for comparing matched pairs in two groups with left-censored data. And while NADA2::cen_signedranktest() is an excellent option, I wrote the following as another. It implements the Paired Prentice-Wilcoxon test, as described in Helsel (2012). I should also acknowledge the orphaned USGS’ orphaned package smwrQW (Lorenz 2017) for its version of the PPW test.\n\n\nlibrary(\"tidyverse\")\nlibrary(\"survival\")\n\nppw_test <- function(\n  x, # numeric\n  y, # numeric\n  x_cen, # logical \n  y_cen, # logical \n  alternative = \"two.sided\", # either \"two.sided\", \"greater\" (x > y), or \"less\" (x < y)\n  flip = TRUE\n) {\n  \n  if(length(x) != length(y))\n    stop(\"Lengths of x and y must be the same for paired data.\")\n  \n  if(any(c(x, y) < 0))\n    stop(\"Negative values in x or y.\")\n  \n  valid_alternative <- pmatch(alternative, c(\"two.sided\", \"greater\", \"less\"))\n  \n  if(is.na(valid_alternative))\n    stop('Invalid choice for alternative, must match \"two.sided\", \"greater\", or \"less\"')\n\n  test_input <- tibble(x_val = x, y_val = y, x_cen, y_cen) %>% \n    na.omit() %>% \n    rowid_to_column() %>% \n    pivot_longer(\n      cols = -rowid,\n      names_to = c(\"group\", \".value\"),\n      names_pattern = \"(.+)_(.+)\"\n    ) %>% \n    mutate(\n      cen = as.numeric(!cen), # 0 is censored, 1 is observed\n      # flip data so that smallest observation becomes longest \"survival time\":\n      # N.B., this rounds the flipped data to 6 decimal places\n      flipped = if(flip) {max(val) + 1 - val} else val,\n      flipped = round(flipped, 6)\n    ) %>% \n    left_join(\n      # estimate survival function:\n      survival::survfit(survival::Surv(flipped, cen) ~ 1, data = .) %>% \n        broom::tidy() %>% \n        mutate(time = round(time, 6)),\n      by = c(\"flipped\" = \"time\")\n    ) %>% \n    mutate(score = if_else(cen == 1, 1 - 2 * estimate, 1 - estimate)) %>% \n    pivot_wider(id_cols = rowid, names_from = group, values_from = score) %>% \n    mutate(d = x - y) %>% \n    summarize(\n      z_ppw = sum(d) / sqrt(sum(d ^ 2)),\n      p_val = if(alternative == \"two.sided\") {2 * pnorm(abs(z_ppw), lower.tail = FALSE)} else\n        if(alternative == \"greater\") {pnorm(-z_ppw, lower.tail = FALSE)} else\n          if(alternative == \"less\") {pnorm(z_ppw, lower.tail = FALSE)} else\n            \"alternative hypothesis is invalid\"\n    )\n  \n  list(\"statistic\" = test_input$z_ppw, \"p.value\" = test_input$p_val)\n  \n}\n\n\n\nThe ppw_test() function works like this:\n\n\nwithr::with_seed(450, { # generate two random normal variables, with left-censoring:\n  tibble( \n    x = rnorm(10, 3, 1),\n    y = rnorm(10, 3, 1),\n    x_cen = x < 2,\n    y_cen = y < 2\n  )\n}) %>% \n  with(ppw_test(x, y, x_cen, y_cen))\n\n\n$statistic\n[1] -0.5628925\n\n$p.value\n[1] 0.5735081\n\nIt also does one-sided tests:\n\n\nwithr::with_seed(23, {\n  tibble( \n    x = rnorm(10, 10, 1),\n    y = rnorm(10, 5, 1),\n    x_cen = x < 10,\n    y_cen = y < 5\n  )\n}) %>% \n  with(ppw_test(x, y, x_cen, y_cen, alternative = \"greater\")) \n\n\n$statistic\n[1] -2.918231\n\n$p.value\n[1] 0.001760118\n\nThe following codes tests that it gives the expected result when applied to the data in Table 9.7 of Helsel (2012). First, here are the data:\n\n\n\n\n\nhelsel <- read_csv(\"helsel_table_9.7 copy.csv\")\n\n\n\n\n\n\nAnd here are the test results. These match the results in Helsel (2012).\n\n\nhelsel %>% \n  mutate(\n    june_cen = str_detect(june, \"<\"),\n    sept_cen = str_detect(september, \"<\"),\n  ) %>% \n  mutate_if(is.character, ~ as.numeric(str_remove(.x, \"<\"))) %>% \n  with(ppw_test(june, september, june_cen, sept_cen, \"less\"))\n\n\n$statistic\n[1] 3.012394\n\n$p.value\n[1] 0.001295979\n\nAnd the following code tests that it gives the expected result on the data of O’Brien and Fleming (1987).\n\n\ntibble::tribble(\n  # from o'brien and fleming, 1987:\n  ~patient, ~close_match, ~poor_match,\n  1, \"37\", 29, \n  2, \"19\", 13, \n  3, \">57\", 15, \n  4, \"93\", 26, \n  5, \"16\", 11, \n  6, \"22\", 17, \n  7, \"20\", 26, \n  8, \"18\", 21, \n  9, \"63\", 43, \n  10, \"29\", 15,\n  11, \">60\", 40\n) %>% \n  mutate(\n    cen_close = str_detect(close_match, \">\"),\n    cen_poor = FALSE,\n    close_match = str_remove(close_match, \">\") %>% \n      as.numeric()\n  ) %>% \n  with(ppw_test(close_match, poor_match, cen_close, cen_poor, alternative = \"less\", flip = FALSE))\n\n\n$statistic\n[1] 2.08696\n\n$p.value\n[1] 0.01844589\n\n\n\n\nHelsel, Dennis R. 2012. Statistics for Censored Environmental Data Using Minitab and R. 2nd ed. Wiley Series in Statistics in Practice. Hoboken, N.J: Wiley.\n\n\nLorenz, Dave. 2017. “SmwrQW–an R Package for Managing and Analyzing Water-Quality Data, Version 0.7.9.” Open File Report. U.S. Geological Survey.\n\n\nO’Brien, Peter C., and Thomas R. Fleming. 1987. “A Paired Prentice-Wilcoxon Test for Censored Paired Data.” Biometrics 43 (1): 169. https://doi.org/10.2307/2531957.\n\n\n\n\n",
    "preview": "posts/2021-07-05-non-parametric-matched-pair-testing-with-left-censored-data/non-parametric-matched-pair-testing-with-left-censored-data_files/figure-html5/helsel-plot-1.png",
    "last_modified": "2021-07-12T15:08:16-03:00",
    "input_file": "non-parametric-matched-pair-testing-with-left-censored-data.utf8.md"
  },
  {
    "path": "posts/2021-06-29-peak-detection-for-qualitative-xrd-analysis-in-r/",
    "title": "Peak detection for qualitative XRD analysis in R",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Ben Trueman",
        "url": {}
      }
    ],
    "date": "2021-06-29",
    "categories": [],
    "contents": "\n\n\n\nThe data, from Li et al. (2021).\n\n\n\nA quick and dirty method of determining phase importance, for plotting purposes only:\n\n\n\n\n\n\nDetect peaks:\n\n\n\nAdd the identified peaks to the plot:\n\n\n\n\n\n\nLi, Bofu, Benjamin F. Trueman, Javier M. Locsin, Yaohuan Gao, Mohammad Shahedur Rahman, Yuri Park, and Graham A. Gagnon. 2021. “Impact of Sodium Silicate on Lead Release from Lead (Ii) Carbonate.” Environmental Science: Water Research & Technology 7 (3): 599–609. https://doi.org/10.1039/D0EW00886A.\n\n\n\n\n",
    "preview": "posts/2021-06-29-peak-detection-for-qualitative-xrd-analysis-in-r/peak-detection-for-qualitative-xrd-analysis-in-r_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-06-30T11:22:51-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-18-lead-solubility-prediction-using-shiny/",
    "title": "Lead solubility prediction using shiny",
    "description": "An R package and shiny app for PHREEQC-based equilibrium lead and copper solubility prediction.",
    "author": [
      {
        "name": "Ben Trueman",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-06-18",
    "categories": [],
    "contents": "\nRecently, I’ve been experimenting with the excellent R package tidyphreeqc (Dunnington 2019), which provides a convenient interface for generating PHREEQC input files (Charlton and Parkhurst 2011; Parkhurst and Appelo 2013). tidyphreeqc incorporates easily into my workflow, and it’s found its way into several recent publications CITE LI.\nI’ve also used it to build a separate package (pbcusol (Trueman 2021)) that handles lead and copper solubility prediction specifically, with curated thermodynamic data and some domain specific features implemented in what is hopefully a straightforward collection of functions. pbcusol is implemented as a shiny app, available here.\npbcusol can be used to generate lead and copper solubility predictions that are comparable with those found in literature CITE SCHOCK, as detailed in the package README on GitHub. (They’re reproduced here using the wesanderson package for colour palettes (Ram and Wickham 2018).)\n\n\n\npbcusol can also be used to generate predicted lead and copper solubility in the presence of humic substances. This is also outlined in the package README, but here is an example of the type of visualization that can be generated. Of course, these predictions should be properly validated—more on that later.\n\n\n\n\n\n\nCharlton, S. R., and D. L. Parkhurst. 2011. “Modules Based on the Geochemical Model Phreeqc for Use in Scripting and Programming Languages.” Computers & Geosciences 37: 1653–63. http://dx.doi.org/10.1016/j.cageo.2011.02.005.\n\n\nDunnington, Dewey. 2019. tidyphreeqc: Tidy Geochemical Modeling Using Phreeqc. https://github.com/paleolimbot/tidyphreeqc.\n\n\nParkhurst, D. L., and C. A. J. Appelo. 2013. Description of Input and Examples for Phreeqc Version 3–a Computer Program for Speciation, Batch-Reaction, One-Dimensional Transport, and Inverse Geochemical Calculations. Vol. book 6. Techniques and Methods. U.S. Geological Survey. https://pubs.usgs.gov/tm/06/a43.\n\n\nRam, Karthik, and Hadley Wickham. 2018. wesanderson: A Wes Anderson Palette Generator. https://CRAN.R-project.org/package=wesanderson.\n\n\nTrueman, Benjamin. 2021. pbcusol: Predict Lead and Copper Solubility. https://github.com/bentrueman/pbcusol.\n\n\n\n\n",
    "preview": "posts/2021-06-18-lead-solubility-prediction-using-shiny/lead-solubility-prediction-using-shiny_files/figure-html5/basic-grid-1.png",
    "last_modified": "2021-07-12T11:01:39-03:00",
    "input_file": "lead-solubility-prediction-using-shiny.utf8.md"
  }
]
